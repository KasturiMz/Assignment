{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e337d714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\\nexample of each.\\n-> Simple linear regression has one dependent and one independent variable. For example: The relationship between height and weight of a person.\\nWhile multiple Linear Regression has one dependent variable but two or more independent variable.For example: The relationship between the housing\\nprice to the area in square feet and the number of bedrooms. \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.\n",
    "-> Simple linear regression has one dependent and one independent variable. For example: The relationship between height and weight of a person.\n",
    "While multiple Linear Regression has one dependent variable but two or more independent variable.For example: The relationship between the housing\n",
    "price to the area in square feet and the number of bedrooms. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5e666c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\\na given dataset?\\n->The assumptions of linear regression are:\\n1.Linear Model: According to this assumption, the relationship between the independent and dependent variables \\n  should be linear. The reason behind this relationship is that if the relationship will be non-linear which is \\n  certainly is the case in the real-world data then the predictions made by our linear regression model will not \\n  be accurate and will vary from the actual observations a lot.\\n2.No Multicolinearity in Data: If the predictor variables are correlated among themselves, then the data is said \\n  to have a multicollinearity problem. High collinearity means that the two variables vary very similarly and \\n  contain the same kind of information. This will leads to redundancy in the dataset. Due to redundancy, only the \\n  complexity of the model increase, and no new information or pattern is learned by the model. \\n3.Homoscedasticity of Residuals or Equal Variances: Homoscedasity is the term that states that the spread residuals \\n  which we are getting from the linear regression model should be homogeneous or equal spaces. If the spread of the \\n  residuals is heterogeneous then the model is called to be an unsatisfactory model. It can be detected with tha help \\n  of scatter plot.\\n4.Predictors are distributed Normally: This assumption ensures that we have equally distributed observations for the \\n  range of each predictor. So at the end of the model training, the predicted values for each test data should be a \\n  normal distribution. One can get an idea of the distribution of the predicted values by plotting density, KDE, or \\n  QQ plots for the predictions.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?\n",
    "->The assumptions of linear regression are:\n",
    "1.Linear Model: According to this assumption, the relationship between the independent and dependent variables \n",
    "  should be linear. The reason behind this relationship is that if the relationship will be non-linear which is \n",
    "  certainly is the case in the real-world data then the predictions made by our linear regression model will not \n",
    "  be accurate and will vary from the actual observations a lot.\n",
    "2.No Multicolinearity in Data: If the predictor variables are correlated among themselves, then the data is said \n",
    "  to have a multicollinearity problem. High collinearity means that the two variables vary very similarly and \n",
    "  contain the same kind of information. This will leads to redundancy in the dataset. Due to redundancy, only the \n",
    "  complexity of the model increase, and no new information or pattern is learned by the model. \n",
    "3.Homoscedasticity of Residuals or Equal Variances: Homoscedasity is the term that states that the spread residuals \n",
    "  which we are getting from the linear regression model should be homogeneous or equal spaces. If the spread of the \n",
    "  residuals is heterogeneous then the model is called to be an unsatisfactory model. It can be detected with tha help \n",
    "  of scatter plot.\n",
    "4.Predictors are distributed Normally: This assumption ensures that we have equally distributed observations for the \n",
    "  range of each predictor. So at the end of the model training, the predicted values for each test data should be a \n",
    "  normal distribution. One can get an idea of the distribution of the predicted values by plotting density, KDE, or \n",
    "  QQ plots for the predictions.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d72a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q3. How do you interpret the slope and intercept in a linear regression model?\\n-> The slope determines the rate of change of the dependent variable with respect to \\nthe independent variable, while the intercept represents the value of the dependent \\nvariable when the independent variable is zero.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q3. How do you interpret the slope and intercept in a linear regression model?\n",
    "-> The slope determines the rate of change of the dependent variable with respect to \n",
    "the independent variable, while the intercept represents the value of the dependent \n",
    "variable when the independent variable is zero.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd635c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Q4. Explain the concept of gradient descent. How is it used in machine learning?\\n->Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. \\nGradient descent in machine learning is simply used to find the values of a function's parameters (coefficients) \\nthat minimize a cost function as far as possible.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "->Gradient Descent is an optimization algorithm for finding a local minimum of a differentiable function. \n",
    "Gradient descent in machine learning is simply used to find the values of a function's parameters (coefficients) \n",
    "that minimize a cost function as far as possible.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53ce0266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\\n->Multiple linear regression is a regression model that estimates the relationship between a quantitative \\ndependent variable and two or more independent variables using a straight line. It has two or more independent\\nvariables while simple linear regression has only one independent variable.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "->Multiple linear regression is a regression model that estimates the relationship between a quantitative \n",
    "dependent variable and two or more independent variables using a straight line. It has two or more independent\n",
    "variables while simple linear regression has only one independent variable.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9e11ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\\naddress this issue?\\n-> If the predictor variables are correlated among themselves, then the data is said \\n  to have a multicollinearity problem. High collinearity means that the two variables vary very similarly and \\n  contain the same kind of information. This will leads to redundancy in the dataset.\\n  The multicollinearity among the variables is detected using the three techniques; correlation coefficients, \\n  variance inflation factor, and eigenvalue method.\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?\n",
    "-> If the predictor variables are correlated among themselves, then the data is said \n",
    "  to have a multicollinearity problem. High collinearity means that the two variables vary very similarly and \n",
    "  contain the same kind of information. This will leads to redundancy in the dataset.\n",
    "  The multicollinearity among the variables is detected using the three techniques; correlation coefficients, \n",
    "  variance inflation factor, and eigenvalue method.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a94d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q7. Describe the polynomial regression model. How is it different from linear regression?\\n->Polynomial regression model is used when the relationship between the dependent and the independent \\nvariables can be represented in the form of a polynomial of the independent variables of nth degree i.e \\nthe relationship is non-linear. It is used for non-linear pattern or relationships while simple regression\\nmodel is used for linear relationship or pattern.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "->Polynomial regression model is used when the relationship between the dependent and the independent \n",
    "variables can be represented in the form of a polynomial of the independent variables of nth degree i.e \n",
    "the relationship is non-linear. It is used for non-linear pattern or relationships while simple regression\n",
    "model is used for linear relationship or pattern.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ceeb7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q8. What are the advantages and disadvantages of polynomial regression compared to linear\\nregression? In what situations would you prefer to use polynomial regression?\\n-> Advantages:\\n1) Polynomial regression is independent of the size of the data set.\\n2) Non-linear problems are solved with good accuracy.\\n3) It gives the best approximation of the correspondence between the output and explanatory \\n(independent) variables.\\n4) A large number of functions can be fit under it. \\n5) Many curvatures can be fit by polynomial regression. \\n\\n->Disadvantages:\\n1) The occurrence of one or two outliers in the dataset can seriously affect the results obtained in\\nperforming the nonlinear polynomial regression analysis.\\n2) The polynomial regression technique is sensitive to outliers.\\n3) For a good bias trade-off selecting the right polynomial degree is very important in analysis.\\n4) There are a small number of model validation tools for the detection of outliers in non-linear\\nregression analysis as compared to linear regression analysis. \\n\\n->The polynomial models can be used in those situations where the relationship between study and \\nexplanatory variables is curvilinear. Sometimes a nonlinear relationship in a small range of explanatory \\nvariable can also be modelled by polynomials.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?\n",
    "-> Advantages:\n",
    "1) Polynomial regression is independent of the size of the data set.\n",
    "2) Non-linear problems are solved with good accuracy.\n",
    "3) It gives the best approximation of the correspondence between the output and explanatory \n",
    "(independent) variables.\n",
    "4) A large number of functions can be fit under it. \n",
    "5) Many curvatures can be fit by polynomial regression. \n",
    "\n",
    "->Disadvantages:\n",
    "1) The occurrence of one or two outliers in the dataset can seriously affect the results obtained in\n",
    "performing the nonlinear polynomial regression analysis.\n",
    "2) The polynomial regression technique is sensitive to outliers.\n",
    "3) For a good bias trade-off selecting the right polynomial degree is very important in analysis.\n",
    "4) There are a small number of model validation tools for the detection of outliers in non-linear\n",
    "regression analysis as compared to linear regression analysis. \n",
    "\n",
    "->The polynomial models can be used in those situations where the relationship between study and \n",
    "explanatory variables is curvilinear. Sometimes a nonlinear relationship in a small range of explanatory \n",
    "variable can also be modelled by polynomials.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff0ea8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
