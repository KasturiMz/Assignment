{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf27c3d1-93b0-42ce-a831-f47cb077c1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWeb scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format.\\nWeb scraping is used in -\\n1. Search engine bots in crawling a site, analyzing its content and then ranking it.\\n2. Price comparison sites deploying bots to auto-fetch prices and product descriptions for allied seller websites.\\n3. Market research companies using scrapers to pull data from forums and social media.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "'''\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format.\n",
    "Web scraping is used in -\n",
    "1. Search engine bots in crawling a site, analyzing its content and then ranking it.\n",
    "2. Price comparison sites deploying bots to auto-fetch prices and product descriptions for allied seller websites.\n",
    "3. Market research companies using scrapers to pull data from forums and social media.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b063359-e527-442b-957a-79688a1ff91b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe different methods used for web scraping are-\\n1. HTML Parsing\\n2. Document Object Model Parsing\\n3. Vertical Aggregation \\n4. XML Path Language\\n5. Google Sheets etc.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2. What are the different methods used for Web Scraping?\n",
    "'''\n",
    "The different methods used for web scraping are-\n",
    "1. HTML Parsing\n",
    "2. Document Object Model Parsing\n",
    "3. Vertical Aggregation \n",
    "4. XML Path Language\n",
    "5. Google Sheets etc.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125d8afb-566c-470e-9da9-de8b48830f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBeautiful Soup is a Python library for getting data out of HTML, XML, and other markup languages. It is used for web scraping.\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3. What is Beautiful Soup? Why is it used?\n",
    "'''\n",
    "Beautiful Soup is a Python library for getting data out of HTML, XML, and other markup languages. It is used for web scraping.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f49df88-d2ac-4932-a940-b4e5e223f952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFlask is used for creating webpage, for web scraping and connecting our web page to a database.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4. Why is flask used in this Web Scraping project?\n",
    "'''\n",
    "Flask is used for creating webpage, for web scraping and connecting our web page to a database.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359c03e4-984f-44b1-8799-585cb06de966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe AWS services used in this project are:\\nCode Pipeline: AWS CodePipeline is a continuous delivery service we can use to model, visualize, and automate the steps required to \\nrelease our software.\\n\\nElastic Beanstalk: It helps us to quickly deploy and manage applications in the AWS Cloud without having to learn about the infrastructure \\nthat runs those applications.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "'''\n",
    "The AWS services used in this project are:\n",
    "Code Pipeline: AWS CodePipeline is a continuous delivery service we can use to model, visualize, and automate the steps required to \n",
    "release our software.\n",
    "\n",
    "Elastic Beanstalk: It helps us to quickly deploy and manage applications in the AWS Cloud without having to learn about the infrastructure \n",
    "that runs those applications.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ee8ab-0977-485c-8e0c-32852d54a039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
